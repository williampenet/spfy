# Fichier : streamlit_app.py

# --- √âtape 1 : Importer les biblioth√®ques n√©cessaires ---
import streamlit as st
import pandas as pd # On importe pandas pour la manipulation des donn√©es
from supabase import create_client, Client
import plotly.express as px
import plotly.graph_objects as go

# --- Configuration de la page (DOIT √™tre en premier) ---
st.set_page_config(page_title="Mon Spotistory", layout="wide", initial_sidebar_state="collapsed")

# --- √âtape 2 : Initialiser la connexion √† Supabase ---
try:
    supabase_url = st.secrets["SUPABASE_URL"]
    supabase_key = st.secrets["SUPABASE_KEY"]
    supabase_client: Client = create_client(supabase_url, supabase_key)
except KeyError as e:
    st.error(f"ERREUR : Les secrets Supabase ne sont pas configur√©s. Cl√© manquante : {e}")
    st.stop()
except Exception as e:
    st.error(f"ERREUR : Impossible de se connecter √† Supabase. D√©tails : {str(e)}")
    st.stop()

# --- √âtape 3 : D√©finir la fonction de chargement (ne change pas) ---
@st.cache_data
def load_spotify_data(_db_client: Client):
    """Charge les donn√©es depuis la table 'tracks' de Supabase."""
    response = _db_client.table('tracks').select('*').execute()
    # On convertit directement les donn√©es en DataFrame pandas
    return pd.DataFrame(response.data)

# --- √âtape 4 : Construire l'interface de l'application ---

st.title("üéµ Mon Historique Spotify")

# --- On charge les donn√©es (ne change pas) ---
df_spotify = load_spotify_data(supabase_client)

# Si le chargement a √©chou√© ou si la table est vide, on arr√™te
if df_spotify.empty:
    st.warning("Aucune donn√©e √† afficher. La table 'tracks' est peut-√™tre vide.")
else:
    # --- D√âBUT DE LA NOUVELLE PARTIE : ANALYSE ET VISUALISATION ---

    st.markdown("### Explorez vos habitudes d'√©coute musicale avec des visualisations interactives")
    st.markdown("---")

    # --- Indicateurs cl√©s (KPIs) ---
    st.header("üìä Statistiques g√©n√©rales")
    total_morceaux = len(df_spotify)
    # Assurez-vous que le nom de la colonne 'artistName' est correct
    total_artistes = df_spotify['master_metadata_album_artist_name'].nunique()
    total_albums = df_spotify['master_metadata_album_album_name'].nunique()
    temps_total_heures = df_spotify['ms_played'].sum() / (1000 * 60 * 60)  # Convertir en heures

    col1, col2, col3, col4 = st.columns(4)
    col1.metric("üéµ Morceaux √©cout√©s", f"{total_morceaux:,}")
    col2.metric("üé§ Artistes uniques", f"{total_artistes:,}")
    col3.metric("üíø Albums uniques", f"{total_albums:,}")
    col4.metric("‚è∞ Temps total", f"{temps_total_heures:.0f}h")

    # --- Top Artistes et Titres par Ann√©e ---
    st.header("üèÜ Vos tops avec r√©partition annuelle")

    # Pr√©parer les donn√©es avec l'ann√©e
    df_with_year = df_spotify.copy()
    df_with_year['timestamp_dt'] = pd.to_datetime(df_with_year['timestamp'], errors='coerce')
    df_with_year['year'] = df_with_year['timestamp_dt'].dt.year

    # Filtrer les donn√©es valides
    df_valid_year = df_with_year[df_with_year['year'].notna()].copy()

    # Cr√©er deux colonnes pour les graphiques
    col_artists, col_tracks = st.columns(2)

    with col_artists:
        st.subheader("Top 10 Artistes par ann√©e")
        
        # Calculer le top 10 des artistes
        top_artists = df_valid_year['master_metadata_album_artist_name'].value_counts().head(10).index
        
        # Cr√©er un DataFrame avec le compte par artiste et ann√©e
        artist_year_counts = df_valid_year[df_valid_year['master_metadata_album_artist_name'].isin(top_artists)].groupby(
            ['master_metadata_album_artist_name', 'year']
        ).size().reset_index(name='count')
        
        # Pivoter pour avoir les ann√©es en colonnes
        artist_pivot = artist_year_counts.pivot(
            index='master_metadata_album_artist_name',
            columns='year',
            values='count'
        ).fillna(0)
        
        # R√©ordonner selon le total d√©croissant
        artist_pivot['total'] = artist_pivot.sum(axis=1)
        artist_pivot = artist_pivot.sort_values('total', ascending=True).drop('total', axis=1)
        
        # Cr√©er le graphique √† barres empil√©es
        fig_artists = go.Figure()
        
        # D√©finir les couleurs par ann√©e
        year_colors = {
            2023: '#FF6B6B',  # Rouge/Rose
            2024: '#4ECDC4',  # Turquoise
            2025: '#45B7D1',  # Bleu clair
        }
        
        # Ajouter une trace pour chaque ann√©e
        for year in sorted(artist_pivot.columns):
            fig_artists.add_trace(go.Bar(
                name=str(int(year)),
                y=artist_pivot.index,
                x=artist_pivot[year],
                orientation='h',
                marker_color=year_colors.get(year, '#95A5A6'),
                hovertemplate='<b>%{y}</b><br>' +
                              f'Ann√©e {int(year)}: %{{x}} √©coutes<br>' +
                              '<extra></extra>'
            ))
        
        fig_artists.update_layout(
            barmode='stack',
            title='Total des √©coutes par artiste et ann√©e',
            xaxis_title='Nombre d\'√©coutes',
            yaxis_title='',
            height=500,
            showlegend=True,
            legend=dict(
                title="Ann√©e",
                orientation="h",
                yanchor="bottom",
                y=1.02,
                xanchor="right",
                x=1
            ),
            margin=dict(l=150)  # Plus d'espace pour les noms d'artistes
        )
        
        st.plotly_chart(fig_artists, use_container_width=True)

    with col_tracks:
        st.subheader("Top 10 Titres par ann√©e")
        
        # Calculer le top 10 des titres
        top_tracks = df_valid_year['master_metadata_track_name'].value_counts().head(10).index
        
        # Cr√©er un DataFrame avec le compte par titre et ann√©e
        track_year_counts = df_valid_year[df_valid_year['master_metadata_track_name'].isin(top_tracks)].groupby(
            ['master_metadata_track_name', 'master_metadata_album_artist_name', 'year']
        ).size().reset_index(name='count')
        
        # Pour l'affichage, combiner titre et artiste
        track_year_counts['display_name'] = track_year_counts['master_metadata_track_name'].str[:30] + '...' + \
                                            ' (' + track_year_counts['master_metadata_album_artist_name'].str[:15] + ')'
        
        # Pivoter pour avoir les ann√©es en colonnes
        track_pivot = track_year_counts.pivot_table(
            index='display_name',
            columns='year',
            values='count',
            aggfunc='sum'
        ).fillna(0)
        
        # R√©ordonner selon le total d√©croissant
        track_pivot['total'] = track_pivot.sum(axis=1)
        track_pivot = track_pivot.sort_values('total', ascending=True).drop('total', axis=1)
        
        # Cr√©er le graphique √† barres empil√©es
        fig_tracks = go.Figure()
        
        # Ajouter une trace pour chaque ann√©e
        for year in sorted(track_pivot.columns):
            fig_tracks.add_trace(go.Bar(
                name=str(int(year)),
                y=track_pivot.index,
                x=track_pivot[year],
                orientation='h',
                marker_color=year_colors.get(year, '#95A5A6'),
                hovertemplate='<b>%{y}</b><br>' +
                              f'Ann√©e {int(year)}: %{{x}} √©coutes<br>' +
                              '<extra></extra>'
            ))
        
        fig_tracks.update_layout(
            barmode='stack',
            title='Total des √©coutes par titre et ann√©e',
            xaxis_title='Nombre d\'√©coutes',
            yaxis_title='',
            height=500,
            showlegend=True,
            legend=dict(
                title="Ann√©e",
                orientation="h",
                yanchor="bottom",
                y=1.02,
                xanchor="right",
                x=1
            ),
            margin=dict(l=200)  # Plus d'espace pour les titres
        )
        
        st.plotly_chart(fig_tracks, use_container_width=True)

    # Statistiques suppl√©mentaires
    st.subheader("üìä Analyse de la diversit√© musicale")

    col1, col2, col3, col4 = st.columns(4)

    # Calculer les m√©triques par ann√©e
    years = sorted(df_valid_year['year'].unique())
    current_year = years[-1] if years else None
    previous_year = years[-2] if len(years) > 1 else None

    with col1:
        if current_year:
            current_artists = df_valid_year[df_valid_year['year'] == current_year]['master_metadata_album_artist_name'].nunique()
            st.metric(f"Artistes √©cout√©s en {int(current_year)}", f"{current_artists:,}")

    with col2:
        if previous_year and current_year:
            prev_artists = df_valid_year[df_valid_year['year'] == previous_year]['master_metadata_album_artist_name'].nunique()
            diff = current_artists - prev_artists
            st.metric(f"√âvolution vs {int(previous_year)}", 
                      f"{'+' if diff > 0 else ''}{diff}",
                      f"{diff/prev_artists*100:+.1f}%")

    with col3:
        # Artistes d√©couverts cette ann√©e
        if current_year and previous_year:
            current_year_artists = set(df_valid_year[df_valid_year['year'] == current_year]['master_metadata_album_artist_name'].unique())
            previous_years_artists = set(df_valid_year[df_valid_year['year'] < current_year]['master_metadata_album_artist_name'].unique())
            new_artists = current_year_artists - previous_years_artists
            st.metric(f"Nouveaux artistes en {int(current_year)}", f"{len(new_artists):,}")

    with col4:
        # Concentration (part du top 10 dans le total)
        if current_year:
            total_plays = len(df_valid_year[df_valid_year['year'] == current_year])
            top10_plays = df_valid_year[df_valid_year['year'] == current_year]['master_metadata_album_artist_name'].value_counts().head(10).sum()
            concentration = top10_plays / total_plays * 100
            st.metric("Concentration Top 10", f"{concentration:.1f}%")

    # Note sur les ann√©es disponibles
    with st.expander("‚ÑπÔ∏è Ann√©es disponibles dans vos donn√©es"):
        years_str = ", ".join([str(int(y)) for y in sorted(df_valid_year['year'].unique())])
        st.write(f"Vos donn√©es couvrent les ann√©es : **{years_str}**")
        
        # Afficher le nombre d'√©coutes par ann√©e
        yearly_counts = df_valid_year['year'].value_counts().sort_index()
        for year, count in yearly_counts.items():
            st.write(f"- **{int(year)}** : {count:,} √©coutes")

    # --- Graphique des √©coutes dans le temps ---
    st.header("üìà √âvolution de vos √©coutes")

    # Pr√©parer les donn√©es de date
    df_copy = df_spotify.copy()

    # Utiliser timestamp en priorit√©, sinon played_date
    if 'timestamp' in df_copy.columns:
        df_copy['date_parsed'] = pd.to_datetime(df_copy['timestamp'], errors='coerce')
    else:
        df_copy['date_parsed'] = pd.to_datetime(df_copy['played_date'], errors='coerce')

    # Filtrer uniquement les donn√©es avec des dates valides
    df_valid_dates = df_copy[df_copy['date_parsed'].notna()].copy()

    if len(df_valid_dates) > 0:
        # Grouper par mois
        ecoutes_par_mois = df_valid_dates.groupby(df_valid_dates['date_parsed'].dt.to_period('M')).size().reset_index()
        ecoutes_par_mois.columns = ['Mois', 'Nombre d\'√©coutes']
        ecoutes_par_mois['Mois'] = ecoutes_par_mois['Mois'].astype(str)
        
        # Cr√©er le graphique
        fig_evolution = px.bar(ecoutes_par_mois, 
                              x='Mois', 
                              y='Nombre d\'√©coutes',
                              title='Nombre d\'√©coutes par mois',
                              color='Nombre d\'√©coutes',
                              color_continuous_scale='Sunset')
        fig_evolution.update_layout(showlegend=False,
                                   coloraxis_showscale=False)
        st.plotly_chart(fig_evolution, use_container_width=True)
    else:
        st.error("Aucune donn√©e avec des dates valides trouv√©e.")

    # --- Graphique de r√©partition par dur√©e ---
    st.header("‚è±Ô∏è R√©partition des titres par dur√©e")
    
    # Convertir ms_played en minutes
    df_spotify['duration_minutes'] = df_spotify['ms_played'] / 60000
    
    # Cr√©er les cat√©gories de dur√©e
    bins = [0, 5, 10, 15, 20, float('inf')]
    labels = ['< 5 min', '5-10 min', '10-15 min', '15-20 min', '> 20 min']
    df_spotify['duration_category'] = pd.cut(df_spotify['duration_minutes'], 
                                              bins=bins, 
                                              labels=labels, 
                                              right=False)
    
    # Compter le nombre de titres par cat√©gorie
    duration_counts = df_spotify['duration_category'].value_counts().sort_index().reset_index()
    duration_counts.columns = ['Tranche de dur√©e', 'Nombre de titres']
    
    # Cr√©er le graphique avec Plotly
    fig_duration = px.bar(duration_counts, 
                         x='Tranche de dur√©e', 
                         y='Nombre de titres',
                         title='Distribution des titres √©cout√©s par dur√©e',
                         color='Nombre de titres',
                         color_continuous_scale='Sunset',
                         text='Nombre de titres')
    
    # Personnaliser l'apparence
    fig_duration.update_traces(texttemplate='%{text}', textposition='outside')
    fig_duration.update_layout(showlegend=False,
                              yaxis_title='Nombre de titres',
                              xaxis_title='Tranches de dur√©e')
    
    st.plotly_chart(fig_duration, use_container_width=True)

    # --- Graphique des heures d'√©coute ---
    st.header("üïê R√©partition par heure de la journ√©e")

    # Convertir timestamp en datetime
    df_spotify['timestamp_dt'] = pd.to_datetime(df_spotify['timestamp'], errors='coerce')

    # Extraire l'heure et le jour de la semaine directement depuis timestamp
    df_spotify['hour'] = df_spotify['timestamp_dt'].dt.hour
    df_spotify['weekday'] = df_spotify['timestamp_dt'].dt.dayofweek
    df_spotify['date_only'] = df_spotify['timestamp_dt'].dt.date

    # Mapper les num√©ros de jour aux noms
    day_names = {0: 'Monday', 1: 'Tuesday', 2: 'Wednesday', 3: 'Thursday', 
                 4: 'Friday', 5: 'Saturday', 6: 'Sunday'}
    df_spotify['weekday_name'] = df_spotify['weekday'].map(day_names)

    # Filtrer les lignes avec timestamp valide
    df_valid_dates = df_spotify[df_spotify['timestamp_dt'].notna()].copy()

    # Afficher le nombre de lignes utilis√©es
    st.info(f"üìä Utilisation de {len(df_valid_dates):,} lignes sur {len(df_spotify):,} ({len(df_valid_dates)/len(df_spotify)*100:.1f}%) pour la heatmap")

    # Compter le nombre d'occurrences de chaque jour de la semaine
    days_count = df_valid_dates.groupby(['weekday', 'date_only']).size().reset_index()
    occurrences_per_day = days_count.groupby('weekday').size().reset_index(name='occurrences')
    occurrences_dict = dict(zip(occurrences_per_day['weekday'], occurrences_per_day['occurrences']))

    # Afficher les statistiques de couverture des donn√©es
    st.subheader("üìä Couverture des donn√©es")
    col1, col2, col3 = st.columns(3)
    with col1:
        if len(df_valid_dates) > 0:
            st.metric("P√©riode couverte", 
                      f"{df_valid_dates['timestamp_dt'].min().strftime('%Y-%m-%d')} √† {df_valid_dates['timestamp_dt'].max().strftime('%Y-%m-%d')}")
        else:
            st.metric("P√©riode couverte", "Pas de dates valides")
    with col2:
        st.metric("Jours avec donn√©es", 
                  f"{df_valid_dates['date_only'].nunique()} jours")
    with col3:
        # Afficher le jour le moins repr√©sent√©
        if occurrences_dict:
            min_day = min(occurrences_dict.items(), key=lambda x: x[1])
            st.metric("Jour le moins couvert", 
                      f"{day_names[min_day[0]]}: {min_day[1]} occurrences")
        else:
            st.metric("Jour le moins couvert", "N/A")

    # Calculer les √©coutes par jour/heure
    if len(df_valid_dates) == 0:
        st.warning("‚ö†Ô∏è Aucune donn√©e valide trouv√©e pour cr√©er la heatmap.")
    else:
        heatmap_data = df_valid_dates.groupby(['weekday_name', 'weekday', 'hour']).size().reset_index(name='count')

        # Ajouter le nombre d'occurrences pour chaque jour
        heatmap_data['day_occurrences'] = heatmap_data['weekday'].map(occurrences_dict)

        # Calculer la vraie moyenne (√©coutes / nombre r√©el d'occurrences du jour)
        heatmap_data['avg_count'] = heatmap_data['count'] / heatmap_data['day_occurrences']

        # Cr√©er un DataFrame complet avec toutes les heures (0-23) et tous les jours
        all_hours = range(24)
        all_days = [(name, num) for num, name in day_names.items()]

        complete_index = pd.MultiIndex.from_product([
            [d[0] for d in all_days],  # weekday_name
            [d[1] for d in all_days],  # weekday number
            all_hours  # hour
        ], names=['weekday_name', 'weekday', 'hour'])

        complete_df = pd.DataFrame(index=complete_index).reset_index()

        # Merger avec les donn√©es r√©elles
        heatmap_data = complete_df.merge(
            heatmap_data[['weekday_name', 'weekday', 'hour', 'avg_count']], 
            on=['weekday_name', 'weekday', 'hour'], 
            how='left'
        ).fillna({'avg_count': 0})

        # Pivoter pour la heatmap
        heatmap_pivot = heatmap_data.pivot_table(
            index='hour',
            columns='weekday',
            values='avg_count',
            fill_value=0
        )

        # R√©ordonner les colonnes
        heatmap_pivot = heatmap_pivot.reindex(columns=range(7))

        # Cr√©er la heatmap
        fig_heure = px.imshow(
            heatmap_pivot.values,
            labels=dict(x="Day", y="Hour", color="Avg plays"),
            x=['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'],
            y=[f"{h:02d}h" for h in range(24)],
            color_continuous_scale='Blues',
            origin='lower',
            title="Weekly listening patterns: average plays per occurrence",
            aspect='auto'
        )

        # Ajouter des annotations pour montrer la couverture
        annotations = []
        for i, day in enumerate(range(7)):
            if day in occurrences_dict:
                annotations.append(
                    dict(
                        text=f"{occurrences_dict[day]}x",
                        x=i,
                        y=-1.5,
                        xref="x",
                        yref="y",
                        showarrow=False,
                        font=dict(size=10, color="gray")
                    )
                )

        fig_heure.update_layout(
            height=800,
            xaxis_title="Day of the week (number shows data coverage)",
            yaxis_title="Hour of the day",
            yaxis=dict(
                tickmode='array',
                tickvals=list(range(24)),
                ticktext=[f"{h:02d}h" for h in range(24)]
            ),
            annotations=annotations
        )

        st.plotly_chart(fig_heure, use_container_width=True)

        # Note sur le fuseau horaire
        with st.expander("‚ÑπÔ∏è Comment lire ce graphique ?"):
            st.write("""
            - **Les couleurs** indiquent le nombre moyen de morceaux √©cout√©s √† chaque heure
            - **Les nombres sous chaque jour** (ex: "45x") indiquent combien de fois ce jour appara√Æt dans vos donn√©es
            - **La moyenne est calcul√©e** en divisant le nombre total d'√©coutes par le nombre r√©el d'occurrences de ce jour
            - **Note**: Les heures sont en UTC (temps universel). Pour la France, ajoutez +1h en hiver, +2h en √©t√©.
            
            Par exemple : Si vous avez 90 √©coutes le lundi √† 19h et que vous avez 45 lundis dans vos donn√©es, 
            la moyenne sera 90 √∑ 45 = 2 morceaux par lundi √† 19h.
            """)

    # --- Graphique de valence dans le temps ---
    st.header("üòä √âvolution de votre humeur musicale")

    # Pr√©parer les donn√©es avec timestamp
    df_valence = df_spotify.copy()
    df_valence['timestamp_dt'] = pd.to_datetime(df_valence['timestamp'], errors='coerce')

    # Filtrer les donn√©es avec valence et timestamp valides
    df_valence_valid = df_valence[
        (df_valence['timestamp_dt'].notna()) & 
        (df_valence['valence'].notna())
    ].copy()

    if len(df_valence_valid) > 0:
        # Grouper par mois et calculer la valence moyenne
        df_valence_valid['year_month'] = df_valence_valid['timestamp_dt'].dt.to_period('M')
        valence_monthly = df_valence_valid.groupby('year_month').agg({
            'valence': ['mean', 'std', 'count']
        }).reset_index()
        
        # Aplatir les colonnes multi-index
        valence_monthly.columns = ['year_month', 'valence_mean', 'valence_std', 'count']
        valence_monthly['year_month_str'] = valence_monthly['year_month'].astype(str)
        
        # Cr√©er le graphique principal avec ligne et zone d'√©cart-type
        fig_valence = go.Figure()
        
        # Ajouter la zone d'√©cart-type
        fig_valence.add_trace(go.Scatter(
            x=valence_monthly['year_month_str'],
            y=valence_monthly['valence_mean'] + valence_monthly['valence_std'],
            fill=None,
            mode='lines',
            line_color='rgba(0,100,80,0)',
            showlegend=False,
            hoverinfo='skip'
        ))
        
        fig_valence.add_trace(go.Scatter(
            x=valence_monthly['year_month_str'],
            y=valence_monthly['valence_mean'] - valence_monthly['valence_std'],
            fill='tonexty',
            mode='lines',
            line_color='rgba(0,100,80,0)',
            name='√âcart-type',
            fillcolor='rgba(68, 138, 255, 0.2)',
            hoverinfo='skip'
        ))
        
        # Ajouter la ligne principale
        fig_valence.add_trace(go.Scatter(
            x=valence_monthly['year_month_str'],
            y=valence_monthly['valence_mean'],
            mode='lines+markers',
            name='Valence moyenne',
            line=dict(color='rgb(68, 138, 255)', width=3),
            marker=dict(size=8),
            hovertemplate='<b>%{x}</b><br>' +
                          'Valence moyenne: %{y:.3f}<br>' +
                          '<extra></extra>'
        ))
        
        # Ajouter une ligne de r√©f√©rence √† 0.5
        fig_valence.add_hline(
            y=0.5, 
            line_dash="dash", 
            line_color="gray",
            annotation_text="Neutre (0.5)",
            annotation_position="right"
        )
        
        # Personnaliser le layout
        fig_valence.update_layout(
            title="√âvolution de la valence musicale (0 = triste, 1 = joyeux)",
            xaxis_title="Mois",
            yaxis_title="Valence moyenne",
            yaxis=dict(range=[0, 1]),
            hovermode='x unified',
            showlegend=True,
            height=500
        )
        
        # Rotation des labels x si n√©cessaire
        if len(valence_monthly) > 20:
            fig_valence.update_xaxis(tickangle=-45)
        
        st.plotly_chart(fig_valence, use_container_width=True)
        
        # Statistiques compl√©mentaires
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            avg_valence = df_valence_valid['valence'].mean()
            st.metric("Valence moyenne globale", f"{avg_valence:.3f}")
            
        with col2:
            # Trouver le mois le plus joyeux
            happiest_month = valence_monthly.loc[valence_monthly['valence_mean'].idxmax()]
            st.metric("Mois le plus joyeux", 
                      happiest_month['year_month_str'],
                      f"{happiest_month['valence_mean']:.3f}")
        
        with col3:
            # Trouver le mois le plus triste
            saddest_month = valence_monthly.loc[valence_monthly['valence_mean'].idxmin()]
            st.metric("Mois le plus m√©lancolique", 
                      saddest_month['year_month_str'],
                      f"{saddest_month['valence_mean']:.3f}")
        
        with col4:
            # Tendance r√©cente (3 derniers mois vs 3 mois d'avant)
            if len(valence_monthly) >= 6:
                recent_avg = valence_monthly.tail(3)['valence_mean'].mean()
                previous_avg = valence_monthly.iloc[-6:-3]['valence_mean'].mean()
                trend = recent_avg - previous_avg
                st.metric("Tendance r√©cente", 
                          "‚Üë Plus joyeux" if trend > 0 else "‚Üì Plus m√©lancolique",
                          f"{abs(trend):.3f}")
            else:
                st.metric("Tendance r√©cente", "Pas assez de donn√©es", "‚Äî")
        
        # Graphique secondaire : Distribution de la valence
        st.subheader("Distribution de la valence")
        
        # Cr√©er l'histogramme
        fig_dist = px.histogram(
            df_valence_valid, 
            x='valence',
            nbins=50,
            title="R√©partition des morceaux par valence",
            labels={'valence': 'Valence', 'count': 'Nombre de morceaux'},
            color_discrete_sequence=['rgb(68, 138, 255)']
        )
        
        # Ajouter des zones color√©es pour l'interpr√©tation
        fig_dist.add_vrect(x0=0, x1=0.3, fillcolor="red", opacity=0.1, 
                           annotation_text="M√©lancolique", annotation_position="top")
        fig_dist.add_vrect(x0=0.3, x1=0.7, fillcolor="yellow", opacity=0.1,
                           annotation_text="Neutre", annotation_position="top")
        fig_dist.add_vrect(x0=0.7, x1=1, fillcolor="green", opacity=0.1,
                           annotation_text="Joyeux", annotation_position="top")
        
        fig_dist.update_layout(
            xaxis=dict(range=[0, 1]),
            showlegend=False,
            height=400
        )
        
        st.plotly_chart(fig_dist, use_container_width=True)
        
        # Explication
        with st.expander("‚ÑπÔ∏è Qu'est-ce que la valence ?"):
            st.write("""
            **La valence** est une mesure Spotify de 0 √† 1 qui d√©crit la positivit√© musicale d'un morceau :
            
            - **0.0 - 0.3** : Morceaux tristes, m√©lancoliques, d√©prim√©s ou en col√®re
            - **0.3 - 0.7** : Morceaux neutres ou ambivalents
            - **0.7 - 1.0** : Morceaux joyeux, euphoriques, heureux
            
            Elle est calcul√©e en analysant le tempo, le mode (majeur/mineur), le timbre et d'autres caract√©ristiques acoustiques.
            """)
            
    else:
        st.warning("‚ö†Ô∏è Pas assez de donn√©es avec valence pour cr√©er ce graphique.")